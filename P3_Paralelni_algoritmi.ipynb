{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayhemy/Smith-Waterman-Using-PyCuda/blob/main/P3_Paralelni_algoritmi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb2I589zO1bT",
        "outputId": "bbb2eba7-cf75-406f-97e5-c287ebc24a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2011.2->pycuda) (2.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2011.2->pycuda) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp38-cp38-linux_x86_64.whl size=646530 sha256=af1fbfd7f7f36353c2c053fe76a59a640a8757ad8ff1bd41f22b603ec0511ba5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/41/0d/7cecb04af969d283ebe4a69579a8b2baec0d010a1ac4159f7e\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69870 sha256=bd654402f1a5e3b6501e31e108efbf5d2d5d2f8587977601c2bf69bf19ca8ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/fc/a9/1e7e56fe02d7f58eaff555f22e79d4fc2d817012291254bae2\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n",
            "Wed Jan 11 18:43:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CUDA paralelna implementacija izačuavanja matrice"
      ],
      "metadata": {
        "id": "YPTxrN58fLXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import math\n",
        "\n",
        "# define CUDA kernel function for diagonal filling\n",
        "mod = SourceModule(\"\"\"\n",
        "    __global__ void diagonal_fill(int *matrix, int diagonal_len, int max_diagonal_len, int *seq1, int *seq2, int n, int m, int gap_penalty) {\n",
        "        int idx = threadIdx.x;\n",
        "        int i = (diagonal_len <= max_diagonal_len) ? idx : diagonal_len % max_diagonal_len + idx;\n",
        "        int j = (diagonal_len <= max_diagonal_len) ? diagonal_len - idx : diagonal_len - (diagonal_len % max_diagonal_len) - idx;\n",
        "        if ((idx < diagonal_len) && i < n && j < m) {\n",
        "            int left_score = (j > 0) ? matrix[i*m + j-1] + gap_penalty : 0;\n",
        "            int up_score = (i > 0) ? matrix[(i-1)*m + j] + gap_penalty : 0;\n",
        "            int match_score = (i > 0 && j > 0) ? matrix[(i-1)*m + j-1] + (seq1[j] == seq2[i] ? 5 : -3) : 0;\n",
        "            matrix[i*m + j] = max(0, max(left_score, max(up_score, match_score)));\n",
        "        }\n",
        "    }\n",
        "\"\"\")\n",
        "\n",
        "def SmithWaterman(seq1, seq2, gap_penalty):\n",
        "    n = len(seq1)\n",
        "    m = len(seq2)\n",
        "    max_diag_len = min(n, m)\n",
        "\n",
        "    # create CUDA arrays for the sequences and the alignment matrix\n",
        "    seq1_gpu = cuda.mem_alloc(seq1.nbytes)\n",
        "    seq2_gpu = cuda.mem_alloc(seq2.nbytes)\n",
        "    matrix_gpu = cuda.mem_alloc(n*m*4)\n",
        "\n",
        "    # copy sequences and matrix to the GPU\n",
        "    cuda.memcpy_htod(seq1_gpu, seq1)\n",
        "    cuda.memcpy_htod(seq2_gpu, seq2)\n",
        "    cuda.memcpy_htod(matrix_gpu, np.zeros((n, m), dtype=np.int32))\n",
        "\n",
        "    # compile the CUDA kernel\n",
        "    diagonal_fill = mod.get_function(\"diagonal_fill\")\n",
        "\n",
        "    # call the kernel for each diagonal\n",
        "    block_size = (max_diag_len, 1, 1)\n",
        "    grid_size = (1, 1, 1)\n",
        "    sum = 0\n",
        "    for i in range(n+m):\n",
        "      # for j in range(i+1):\n",
        "      #   indexes.append(np.array([i-j,j], dtype=np.int32))\n",
        "      # indexes = np.array(indexes)\n",
        "      # indexes_gpu = cuda.mem_alloc(indexes.nbytes)\n",
        "      # cuda.memcpy_htod(indexes_gpu, indexes)\n",
        "      duration = diagonal_fill(matrix_gpu, np.int32(i), np.int32(max_diag_len), seq1_gpu, seq2_gpu, np.int32(n), np.int32(m), np.int32(gap_penalty), block=block_size, grid=grid_size, time_kernel=True)\n",
        "      sum += duration\n",
        "\n",
        "    print(sum, 'ms')\n",
        "    # copy matrix back from GPU to host\n",
        "    matrix = np.empty((n, m), dtype=np.int32)\n",
        "    cuda.memcpy_dtoh(matrix, matrix_gpu)\n",
        "    return matrix\n",
        "\n",
        "def create_alignment_matrix(seq1, seq2, match_score=5, mismatch_score=-3, gap_score=-9):\n",
        "    rows = len(seq1)\n",
        "    cols = len(seq2)\n",
        "    # Create the alignment matrix filled with 0\n",
        "    alignment_matrix = np.zeros((rows,cols), dtype = int)\n",
        "\n",
        "    # fill the matrix with scores\n",
        "    for i in range(1, rows):\n",
        "        for j in range(1, cols):\n",
        "            # calculate the scores based on the surrounding cells\n",
        "            to_add = 0\n",
        "            if i <= cols and j < rows :\n",
        "              if seq1[j] == seq2[i]:\n",
        "                to_add = 5\n",
        "              else:\n",
        "                to_add = -3\n",
        "              diagonal_score = alignment_matrix[i-1][j-1] + to_add\n",
        "              up_score = alignment_matrix[i-1][j] + gap_score\n",
        "              left_score = alignment_matrix[i][j-1] + gap_score\n",
        "              alignment_matrix[i][j] = max(0, diagonal_score, up_score, left_score)\n",
        "    return alignment_matrix\n",
        "\n",
        "seq1 = '0CAGCCUCGCUUAG'\n",
        "seq2 = '0AAUGCCAUUGCCGG'\n",
        "gap_penalty = -9\n",
        "print(np.array(list(seq1)))\n",
        "print(np.array(list(seq2)))\n",
        "matrix = SmithWaterman(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "matrix1 = create_alignment_matrix(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "# np.insert(matrix1, 0, int(seq1),axis = 0)\n",
        "# np.insert(matrix1, 1, int(seq2),axis = 1)\n",
        "print(matrix)\n",
        "print()\n",
        "print(matrix1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6WfUux3PBAV",
        "outputId": "01a020b1-8a06-480d-f60f-366dbafc6191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' 'C' 'A' 'G' 'C' 'C' 'U' 'C' 'G' 'C' 'U' 'U' 'A' 'G']\n",
            "['0' 'A' 'A' 'U' 'G' 'C' 'C' 'A' 'U' 'U' 'G' 'C' 'C' 'G' 'G']\n",
            "0.00039386749267578125 ms\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  2]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  6]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  1]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n",
            "\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  0]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  0]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  0]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. CUDA paralelna implementacija pronalaženja optimalne vrednosti poravanja"
      ],
      "metadata": {
        "id": "pivIjsrwfApJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cuda_alloc(*args):\n",
        "  return [cuda.mem_alloc(arg.nbytes) for arg in args]\n",
        "\n",
        "\n",
        "def to_cuda(*args):\n",
        "  cuda_ptrs = cuda_alloc(*args)\n",
        "  for dst, src in zip(cuda_ptrs, args):\n",
        "    cuda.memcpy_htod(dst, src)\n",
        "  return cuda_ptrs\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    __global__ void reduce(int *a, float *result, int width){\n",
        "\n",
        "      int idx = threadIdx.x;\n",
        "\n",
        "      for(unsigned int s=1; s < blockDim.x; s *= 2) {\n",
        "\n",
        "         if (idx % (2*s) == 0){\n",
        "            a[idx] = max(a[idx], a[idx + s]);\n",
        "          }\n",
        "          __syncthreads();\n",
        "      }\n",
        "\n",
        "      // write result for this block to global mem\n",
        "      if (idx == 0){\n",
        "        result[0] = a[0];\n",
        "      }\n",
        "\n",
        "    }\n",
        "  \"\"\")\n",
        "\n",
        "\n",
        "reduction_kernel = mod.get_function(\"reduce\")\n",
        "\n",
        "matrix_gpu = cuda.mem_alloc(matrix.shape[0] * matrix.shape[1] *4)\n",
        "# cuda.memcpy_htod(matrix_gpu, matrix)\n",
        "\n",
        "matrix_gpu = gpuarray.to_gpu(matrix)\n",
        "# matrix_gpu = cuda_alloc(matrix)\n",
        "# to_cuda(matrix_gpu)\n",
        "print(matrix)\n",
        "# cuda.memcpy_htod(matrix_gpu, np.zeros((matrix.shape[0], matrix.shape[1]), dtype=np.int32))\n",
        "\n",
        "result = np.zeros(1, dtype=np.float32)\n",
        "result_cuda = to_cuda(result)[0]\n",
        "\n",
        "reduction_kernel(matrix_gpu, result_cuda, np.int32(matrix.shape[1]),block=(matrix.shape[0] * matrix.shape[1], 1, 1), grid=(1, 1, 1))\n",
        "\n",
        "cuda.memcpy_dtoh(result, result_cuda)\n",
        "\n",
        "print(np.round(result,1))"
      ],
      "metadata": {
        "id": "ILGEWWUtPDdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c03b736-888e-4035-bbc3-77895244062c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  2]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  6]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  1]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n",
            "[18.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cuda_alloc(*args):\n",
        "  return [cuda.mem_alloc(arg.nbytes) for arg in args]\n",
        "\n",
        "\n",
        "def to_cuda(*args):\n",
        "  cuda_ptrs = cuda_alloc(*args)\n",
        "  for dst, src in zip(cuda_ptrs, args):\n",
        "    cuda.memcpy_htod(dst, src)\n",
        "  return cuda_ptrs\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    __global__ void reduce(int *a, float *result, int width){\n",
        "\n",
        "      int idx = threadIdx.x + threadIdx.y*width ;\n",
        "\n",
        "      for(unsigned int s=1; s < blockDim.x + blockDim.y*width; s *= 2) {\n",
        "\n",
        "         if (idx % (2*s) == 0){\n",
        "            a[idx] = max(a[idx], a[idx + s]);\n",
        "          }\n",
        "          __syncthreads();\n",
        "      }\n",
        "\n",
        "      // write result for this block to global mem\n",
        "      if (idx == 1){\n",
        "        result[0] = a[0];\n",
        "      }\n",
        "\n",
        "    }\n",
        "  \"\"\")\n",
        "\n",
        "\n",
        "reduction_kernel = mod.get_function(\"reduce\")\n",
        "\n",
        "matrix_gpu = cuda.mem_alloc(matrix.shape[0] * matrix.shape[1] *4)\n",
        "# cuda.memcpy_htod(matrix_gpu, matrix)\n",
        "\n",
        "matrix_gpu = gpuarray.to_gpu(matrix)\n",
        "# matrix_gpu = cuda_alloc(matrix)\n",
        "# to_cuda(matrix_gpu)\n",
        "print(matrix)\n",
        "# cuda.memcpy_htod(matrix_gpu, np.zeros((matrix.shape[0], matrix.shape[1]), dtype=np.int32))\n",
        "\n",
        "result = np.zeros(1, dtype=np.float32)\n",
        "result_cuda = to_cuda(result)[0]\n",
        "\n",
        "reduction_kernel(matrix_gpu, result_cuda, np.int32(matrix.shape[1]),block=(matrix.shape[1], matrix.shape[0], 1), grid=(1, 1, 1))\n",
        "\n",
        "cuda.memcpy_dtoh(result, result_cuda)\n",
        "\n",
        "print(np.round(result,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-_eRB_pDk7a",
        "outputId": "1d2cbe50-6b6e-407b-93f5-5575a5ba5814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  2]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  6]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  1]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n",
            "[18.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Upotreba deljene i konstante memorije\n",
        "a) Konstantna memorija\n"
      ],
      "metadata": {
        "id": "ak1AUhnje1ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.gpuarray as gpuarray\n",
        "\n",
        "# define CUDA kernel function for diagonal filling\n",
        "mod = SourceModule(\"\"\"\n",
        "      __constant__  float seq1[14];\n",
        "      __constant__  float seq2[15];\n",
        "\n",
        "\n",
        "    __global__ void diagonal_fill_adv(int *matrix, int diagonal_len, int max_diagonal_len, int n, int m, int gap_penalty) {\n",
        "\n",
        "        int idx = threadIdx.x;\n",
        "\n",
        "        int i = (diagonal_len <= max_diagonal_len) ? idx : diagonal_len % max_diagonal_len + idx;\n",
        "        int j = (diagonal_len <= max_diagonal_len) ? diagonal_len - idx : diagonal_len - (diagonal_len % max_diagonal_len) - idx;\n",
        "        if ((idx < diagonal_len) && i < n && j < m) {\n",
        "            int left_score = (j > 0) ? matrix[i*m + j-1] + gap_penalty : 0;\n",
        "            int up_score = (i > 0) ? matrix[(i-1)*m + j] + gap_penalty : 0;\n",
        "            int match_score = (i > 0 && j > 0) ? matrix[(i-1)*m + j-1] + (seq1[j] == seq2[i] ? 5 : -3) : 0;\n",
        "            matrix[i*m + j] = max(0, max(left_score, max(up_score, match_score)));\n",
        "        }\n",
        "    }\n",
        "\"\"\")\n",
        "\n",
        "def SmithWatermanAdv(seq1, seq2, gap_penalty):\n",
        "    n = len(seq1)\n",
        "    m = len(seq2)\n",
        "    max_diag_len = min(n, m)\n",
        "\n",
        "    # create CUDA arrays for the sequences and the alignment matrix\n",
        "\n",
        "    matrix_gpu = cuda.mem_alloc(n*m*4)\n",
        "\n",
        "    # za shared\n",
        "    # seq1_cuda = cuda.mem_alloc(seq1.nbytes)\n",
        "    # seq2_cuda = cuda.mem_alloc(seq2.nbytes)\n",
        "    # za const zakomentarisana prosla dva reda i otkomentarisana sledeca dva\n",
        "    seq1_cuda = mod.get_global('seq1')[0]\n",
        "    seq2_cuda = mod.get_global('seq2')[0]\n",
        "\n",
        "    cuda.memcpy_htod(seq1_cuda, seq1)\n",
        "    cuda.memcpy_htod(seq2_cuda, seq2)\n",
        "\n",
        "\n",
        "    # copy sequences and matrix to the GPU\n",
        "    cuda.memcpy_htod(matrix_gpu, np.zeros((n, m), dtype=np.int32))\n",
        "\n",
        "    # compile the CUDA kernel\n",
        "    diagonal_fill = mod.get_function(\"diagonal_fill_adv\")\n",
        "\n",
        "    # call the kernel for each diagonal\n",
        "    block_size = (max_diag_len, 1, 1)\n",
        "    grid_size = (1, 1, 1)\n",
        "    sum = 0\n",
        "    for i in range(n+m):\n",
        "      # for j in range(i+1):\n",
        "      #   indexes.append(np.array([i-j,j], dtype=np.int32))\n",
        "      # indexes = np.array(indexes)\n",
        "      # indexes_gpu = cuda.mem_alloc(indexes.nbytes)\n",
        "      # cuda.memcpy_htod(indexes_gpu, indexes)\n",
        "      duration = diagonal_fill(matrix_gpu, np.int32(i), np.int32(max_diag_len), np.int32(n), np.int32(m), np.int32(gap_penalty), block=block_size, grid=grid_size, time_kernel=True)\n",
        "      sum += duration\n",
        "\n",
        "    print(sum, 'ms')\n",
        "\n",
        "    # copy matrix back from GPU to host\n",
        "    matrix = np.empty((n, m), dtype=np.int32)\n",
        "    cuda.memcpy_dtoh(matrix, matrix_gpu)\n",
        "    return matrix\n",
        "\n",
        "seq1 = '0CAGCCUCGCUUAG'\n",
        "seq2 = '0AAUGCCAUUGCCGG'\n",
        "gap_penalty = -9\n",
        "print(np.array(list(seq1)))\n",
        "print(np.array(list(seq2)))\n",
        "matrix = SmithWatermanAdv(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "matrix1 = create_alignment_matrix(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "# np.insert(matrix1, 0, int(seq1),axis = 0)\n",
        "# np.insert(matrix1, 1, int(seq2),axis = 1)\n",
        "print(matrix)\n",
        "print()\n",
        "print(matrix1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWRZkQtIXt6Z",
        "outputId": "934dae2d-1b65-4b18-a5ac-82c0b25fb0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' 'C' 'A' 'G' 'C' 'C' 'U' 'C' 'G' 'C' 'U' 'U' 'A' 'G']\n",
            "['0' 'A' 'A' 'U' 'G' 'C' 'C' 'A' 'U' 'U' 'G' 'C' 'C' 'G' 'G']\n",
            "0.00042891502380371094 ms\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  2]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  6]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  1]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n",
            "\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  0]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  0]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  0]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Deljena memorija"
      ],
      "metadata": {
        "id": "nP6C0Tvyx6hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.gpuarray as gpuarray\n",
        "\n",
        "# define CUDA kernel function for diagonal filling\n",
        "mod = SourceModule(\"\"\"\n",
        "    __global__ void diagonal_fill(int *matrix, int diagonal_len, int max_diagonal_len, int *seq1, int *seq2, int n, int m, int gap_penalty) {\n",
        "\n",
        "          __shared__ int seq1_shared[14*4];\n",
        "          __shared__ int seq2_shared[14*4];\n",
        "\n",
        "          int idx = threadIdx.x;\n",
        "\n",
        "          if (threadIdx.x < n) {\n",
        "              seq1_shared[threadIdx.x] = seq1[threadIdx.x];\n",
        "          }\n",
        "          __syncthreads();\n",
        "\n",
        "          if (threadIdx.x < m) {\n",
        "              seq2_shared[threadIdx.x] = seq2[threadIdx.x];\n",
        "          }\n",
        "          __syncthreads();\n",
        "\n",
        "          int i = (diagonal_len <= max_diagonal_len) ? idx : diagonal_len % max_diagonal_len + idx;\n",
        "          int j = (diagonal_len <= max_diagonal_len) ? diagonal_len - idx : diagonal_len - (diagonal_len % max_diagonal_len) - idx;\n",
        "          if ((idx < diagonal_len) && i < n && j < m) {\n",
        "              int left_score = (j > 0) ? matrix[i*m + j-1] + gap_penalty : 0;\n",
        "              int up_score = (i > 0) ? matrix[(i-1)*m + j] + gap_penalty : 0;\n",
        "              int match_score = (i > 0 && j > 0) ? matrix[(i-1)*m + j-1] + (seq1_shared[j] == seq2_shared[i] ? 5 : -3) : 0;\n",
        "              matrix[i*m + j] = max(0, max(left_score, max(up_score, match_score)));\n",
        "          }\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "def SmithWaterman(seq1, seq2, gap_penalty):\n",
        "    n = len(seq1)\n",
        "    m = len(seq2)\n",
        "    max_diag_len = min(n, m)\n",
        "\n",
        "    # create CUDA arrays for the sequences and the alignment matrix\n",
        "    seq1_gpu = cuda.mem_alloc(seq1.nbytes)\n",
        "    seq2_gpu = cuda.mem_alloc(seq2.nbytes)\n",
        "    matrix_gpu = cuda.mem_alloc(n*m*4)\n",
        "\n",
        "    # copy sequences and matrix to the GPU\n",
        "    cuda.memcpy_htod(seq1_gpu, seq1)\n",
        "    cuda.memcpy_htod(seq2_gpu, seq2)\n",
        "    cuda.memcpy_htod(matrix_gpu, np.zeros((n, m), dtype=np.int32))\n",
        "\n",
        "    # compile the CUDA kernel\n",
        "    diagonal_fill = mod.get_function(\"diagonal_fill\")\n",
        "\n",
        "    # call the kernel for each diagonal\n",
        "    block_size = (max_diag_len, 1, 1)\n",
        "    grid_size = (1, 1, 1)\n",
        "    sum = 0\n",
        "    for i in range(n+m):\n",
        "      # for j in range(i+1):\n",
        "      #   indexes.append(np.array([i-j,j], dtype=np.int32))\n",
        "      # indexes = np.array(indexes)\n",
        "      # indexes_gpu = cuda.mem_alloc(indexes.nbytes)\n",
        "      # cuda.memcpy_htod(indexes_gpu, indexes)\n",
        "      duration = diagonal_fill(matrix_gpu, np.int32(i), np.int32(max_diag_len), seq1_gpu, seq2_gpu, np.int32(n), np.int32(m), np.int32(gap_penalty), block=block_size, grid=grid_size, time_kernel=True)\n",
        "      sum += duration\n",
        "\n",
        "    print(sum, 'ms')\n",
        "    # copy matrix back from GPU to host\n",
        "    matrix = np.empty((n, m), dtype=np.int32)\n",
        "    cuda.memcpy_dtoh(matrix, matrix_gpu)\n",
        "    return matrix\n",
        "\n",
        "def create_alignment_matrix(seq1, seq2, match_score=5, mismatch_score=-3, gap_score=-9):\n",
        "    rows = len(seq1)\n",
        "    cols = len(seq2)\n",
        "    # Create the alignment matrix filled with 0\n",
        "    alignment_matrix = np.zeros((rows,cols), dtype = int)\n",
        "\n",
        "    # fill the matrix with scores\n",
        "    for i in range(1, rows):\n",
        "        for j in range(1, cols):\n",
        "            # calculate the scores based on the surrounding cells\n",
        "            to_add = 0\n",
        "            if i <= cols and j < rows :\n",
        "              if seq1[j] == seq2[i]:\n",
        "                to_add = 5\n",
        "              else:\n",
        "                to_add = -3\n",
        "              diagonal_score = alignment_matrix[i-1][j-1] + to_add\n",
        "              up_score = alignment_matrix[i-1][j] + gap_score\n",
        "              left_score = alignment_matrix[i][j-1] + gap_score\n",
        "              alignment_matrix[i][j] = max(0, diagonal_score, up_score, left_score)\n",
        "    return alignment_matrix\n",
        "\n",
        "seq1 = '0CAGCCUCGCUUAG'\n",
        "seq2 = '0AAUGCCAUUGCCGG'\n",
        "gap_penalty = -9\n",
        "print(np.array(list(seq1)))\n",
        "print(np.array(list(seq2)))\n",
        "matrix = SmithWaterman(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "matrix1 = create_alignment_matrix(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "# np.insert(matrix1, 0, int(seq1),axis = 0)\n",
        "# np.insert(matrix1, 1, int(seq2),axis = 1)\n",
        "print(matrix)\n",
        "print()\n",
        "print(matrix1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_LksDwyfc84",
        "outputId": "a72fa087-0989-42a6-944f-671c58cea63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' 'C' 'A' 'G' 'C' 'C' 'U' 'C' 'G' 'C' 'U' 'U' 'A' 'G']\n",
            "['0' 'A' 'A' 'U' 'G' 'C' 'C' 'A' 'U' 'U' 'G' 'C' 'C' 'G' 'G']\n",
            "0.0003788471221923828 ms\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  5]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  5]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  2]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  5]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  6]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  1]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n",
            "\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  5  0  0  0  0  0  0  0  0  0  5  0  0]\n",
            " [ 0  0  5  2  0  0  0  0  0  0  0  0  5  2  0]\n",
            " [ 0  0  0  2  0  0  5  0  0  0  5  5  0  2  0]\n",
            " [ 0  0  0  5  0  0  0  2  5  0  0  2  2  5  0]\n",
            " [ 0  5  0  0 10  5  0  5  0 10  1  0  0  0  0]\n",
            " [ 0  5  2  0  5 15  6  5  2  5  7  0  0  0  0]\n",
            " [ 0  0 10  1  0  6 12  3  2  0  2  4  5  0  0]\n",
            " [ 0  0  1  7  0  0 11  9  0  0  5  7  1  2  0]\n",
            " [ 0  0  0  0  4  0  5  8  6  0  5 10  4  0  0]\n",
            " [ 0  0  0  5  0  1  0  2 13  4  0  2  7  9  0]\n",
            " [ 0  5  0  0 10  5  0  5  4 18  9  0  0  4  0]\n",
            " [ 0  5  2  0  5 15  6  5  2  9 15  6  0  0  0]\n",
            " [ 0  0  2  7  0  6 12  3 10  1  6 12  3  5  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Podrška za dugačke sekvence"
      ],
      "metadata": {
        "id": "L0qbEXv_MmrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import math\n",
        "\n",
        "# define CUDA kernel function for diagonal filling\n",
        "mod = SourceModule(\"\"\"\n",
        "    __global__ void diagonal_fill(int *matrix, int diagonal_len, int max_diagonal_len, int *seq1, int *seq2, int n, int m, int gap_penalty) {\n",
        "        //int idx = threadIdx.x;\n",
        "        long idx = threadIdx.x + blockDim.x*blockIdx.x + threadIdx.y*width + blockDim.y*blockIdx.y*width;\n",
        "        int i = (diagonal_len <= max_diagonal_len) ? idx : diagonal_len % max_diagonal_len + idx;\n",
        "        int j = (diagonal_len <= max_diagonal_len) ? diagonal_len - idx : diagonal_len - (diagonal_len % max_diagonal_len) - idx;\n",
        "        if ((idx < diagonal_len) && i < n && j < m) {\n",
        "            int left_score = (j > 0) ? matrix[i*m + j-1] + gap_penalty : 0;\n",
        "            int up_score = (i > 0) ? matrix[(i-1)*m + j] + gap_penalty : 0;\n",
        "            int match_score = (i > 0 && j > 0) ? matrix[(i-1)*m + j-1] + (seq1[j] == seq2[i] ? 5 : -3) : 0;\n",
        "            matrix[i*m + j] = max(0, max(left_score, max(up_score, match_score)));\n",
        "        }\n",
        "    }\n",
        "\"\"\")\n",
        "\n",
        "def SmithWaterman(seq1, seq2, gap_penalty):\n",
        "    n = len(seq1)\n",
        "    m = len(seq2)\n",
        "    max_diag_len = min(n, m)\n",
        "\n",
        "    # create CUDA arrays for the sequences and the alignment matrix\n",
        "    seq1_gpu = cuda.mem_alloc(seq1.nbytes)\n",
        "    seq2_gpu = cuda.mem_alloc(seq2.nbytes)\n",
        "    matrix_gpu = cuda.mem_alloc(n*m*4)\n",
        "\n",
        "    # copy sequences and matrix to the GPU\n",
        "    cuda.memcpy_htod(seq1_gpu, seq1)\n",
        "    cuda.memcpy_htod(seq2_gpu, seq2)\n",
        "    cuda.memcpy_htod(matrix_gpu, np.zeros((n, m), dtype=np.int32))\n",
        "\n",
        "    # compile the CUDA kernel\n",
        "    diagonal_fill = mod.get_function(\"diagonal_fill\")\n",
        "\n",
        "    # call the kernel for each diagonal\n",
        "    block_size = (32, 32, 1)\n",
        "    grid=(math.ceil(a.shape[1]/32), math.ceil(a.shape[0]/32), 1))\n",
        "    sum = 0\n",
        "    for i in range(n+m):\n",
        "      # for j in range(i+1):\n",
        "      #   indexes.append(np.array([i-j,j], dtype=np.int32))\n",
        "      # indexes = np.array(indexes)\n",
        "      # indexes_gpu = cuda.mem_alloc(indexes.nbytes)\n",
        "      # cuda.memcpy_htod(indexes_gpu, indexes)\n",
        "      duration = diagonal_fill(matrix_gpu, np.int32(i), np.int32(max_diag_len), seq1_gpu, seq2_gpu, np.int32(n), np.int32(m), np.int32(gap_penalty), block=block_size, grid=grid_size, time_kernel=True)\n",
        "      sum += duration\n",
        "\n",
        "    print(sum, 'ms')\n",
        "    # copy matrix back from GPU to host\n",
        "    matrix = np.empty((n, m), dtype=np.int32)\n",
        "    cuda.memcpy_dtoh(matrix, matrix_gpu)\n",
        "    return matrix\n",
        "\n",
        "def create_alignment_matrix(seq1, seq2, match_score=5, mismatch_score=-3, gap_score=-9):\n",
        "    rows = len(seq1)\n",
        "    cols = len(seq2)\n",
        "    # Create the alignment matrix filled with 0\n",
        "    alignment_matrix = np.zeros((rows,cols), dtype = int)\n",
        "\n",
        "    # fill the matrix with scores\n",
        "    for i in range(1, rows):\n",
        "        for j in range(1, cols):\n",
        "            # calculate the scores based on the surrounding cells\n",
        "            to_add = 0\n",
        "            if i <= cols and j < rows :\n",
        "              if seq1[j] == seq2[i]:\n",
        "                to_add = 5\n",
        "              else:\n",
        "                to_add = -3\n",
        "              diagonal_score = alignment_matrix[i-1][j-1] + to_add\n",
        "              up_score = alignment_matrix[i-1][j] + gap_score\n",
        "              left_score = alignment_matrix[i][j-1] + gap_score\n",
        "              alignment_matrix[i][j] = max(0, diagonal_score, up_score, left_score)\n",
        "    return alignment_matrix\n",
        "\n",
        "seq1 = '0CAGCCUCGCUUAG'\n",
        "seq2 = '0AAUGCCAUUGCCGG'\n",
        "gap_penalty = -9\n",
        "print(np.array(list(seq1)))\n",
        "print(np.array(list(seq2)))\n",
        "matrix = SmithWaterman(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "matrix1 = create_alignment_matrix(np.array(list(seq1)),np.array(list(seq2)), gap_penalty)\n",
        "# np.insert(matrix1, 0, int(seq1),axis = 0)\n",
        "# np.insert(matrix1, 1, int(seq2),axis = 1)\n",
        "print(matrix)\n",
        "print()\n",
        "print(matrix1)"
      ],
      "metadata": {
        "id": "ax1WsW7lMpJh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}